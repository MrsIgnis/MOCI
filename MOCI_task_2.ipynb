{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe6xQG7Eh7Y3CKZH8jN7aB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrsIgnis/MOCI/blob/main/MOCI_task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5dTSOR2ykbnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2cbc386-b386-4a24-f193-6a7f8328046a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pymorphy3\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "6DXJcczbnCG7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjXdZ_3nFpS",
        "outputId": "0d482320-31be-4b39-e39e-67d699d48800"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_ru = set(stopwords.words(\"russian\"))\n",
        "stop_words_en = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "u1MuN5XqnHvz"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma_ru = pymorphy3.MorphAnalyzer()\n",
        "lemma_en = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "jO-SsqvRnK6l"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = ['/content/test_1.txt', '/content/test_2.txt', '/content/test_3.txt']\n",
        "texts = [open(path, 'r', encoding='utf-8').read() for path in file_paths]\n",
        "text_1, text_2, text_3 = texts\n",
        "print(text_1, text_2, text_3, sep='\\n' + '-' * 30 + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN68mG6CnNW-",
        "outputId": "ba4b14f1-4439-4c41-f87e-e751d71c6246"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Когда скромняга бард отдыхал от дел\n",
            "С Геральтом из Ривии он песню эту пел.\n",
            "Сразился Белый Волк с велиречивым чертом\n",
            "Эльфов покромсал несчетные когорты.\n",
            "------------------------------\n",
            "Целился тот черт мне рогом прямо в глаз\n",
            "И тут Ведьмак крикнул «Вот твой смертный час!»\n",
            "\n",
            "Ведьмаку заплатите чеканной монетой, чеканной монетой,\n",
            "Ведьмаку заплатите – зачтется все это вам!\n",
            "------------------------------\n",
            "Он эльфов всех прогнал за дальний перевал\n",
            "Высокие горы на вечный привал\n",
            "\n",
            "Он бьет не в бровь, а в глаз, был ранен много раз\n",
            "Он людям товарищ всегда он за нас\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Применить к текстам лемматизацию, удаление стоп слов и токенизацию по словам**"
      ],
      "metadata": {
        "id": "A2_fwq-1xBp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_russian(word: str) -> bool:\n",
        "    return bool(re.search('[а-яё]', word, re.IGNORECASE))\n",
        "\n",
        "def is_english(word: str) -> bool:\n",
        "    return bool(re.search('[a-z]', word, re.IGNORECASE))"
      ],
      "metadata": {
        "id": "RHoJZz93xHft"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(texts: list[str]) -> list[list[str]]:\n",
        "    processed_texts = []\n",
        "\n",
        "    for text in texts:\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^а-яёa-z\\s]', '', text, flags=re.IGNORECASE)\n",
        "        words = word_tokenize(text)\n",
        "        processed_words = []\n",
        "\n",
        "        for word in words:\n",
        "            if word not in stop_words_ru and word not in stop_words_en:\n",
        "                if is_russian(word):\n",
        "                    lemma = lemma_ru.parse(word)[0].normal_form\n",
        "                elif is_english(word):\n",
        "                    lemma = lemma_en.lemmatize(word)\n",
        "                else:\n",
        "                    lemma = word\n",
        "                processed_words.append(lemma)\n",
        "\n",
        "        processed_texts.append(processed_words)\n",
        "\n",
        "    return processed_texts"
      ],
      "metadata": {
        "id": "n8pG7oFExKtr"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_texts = preprocessing(texts)\n",
        "for i, processed_text in enumerate(processed_texts, start=1):\n",
        "    print(f\"Обработанный текст {i}:\")\n",
        "    print(processed_text)\n",
        "    print('-' * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avnk0122ye5e",
        "outputId": "d649332f-0621-4099-a8c8-1b69b5a84e43"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработанный текст 1:\n",
            "['скромняга', 'бард', 'отдыхать', 'дело', 'геральт', 'ривия', 'песня', 'петь', 'сразиться', 'белый', 'волк', 'велиречивый', 'чёрт', 'эльф', 'покромсать', 'несчётный', 'когорта']\n",
            "------------------------------\n",
            "Обработанный текст 2:\n",
            "['целиться', 'черта', 'рог', 'прямо', 'глаз', 'ведьмак', 'крикнуть', 'твой', 'смертный', 'час', 'ведьмак', 'заплатить', 'чеканный', 'монета', 'чеканный', 'монета', 'ведьмак', 'заплатить', 'зачесться', 'это']\n",
            "------------------------------\n",
            "Обработанный текст 3:\n",
            "['эльф', 'прогнать', 'дальний', 'перевал', 'высокий', 'гора', 'вечный', 'привал', 'бить', 'бровь', 'глаз', 'ранить', 'человек', 'товарищ']\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_documents = []\n",
        "for i in processed_texts:\n",
        "    preprocessed_documents.append(i)\n",
        "print(\"Обработанные тексты в одном списке:\", preprocessed_documents, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UufOu9RxzSAb",
        "outputId": "4c20c5a4-1423-43cc-ab27-752a12f6fa40"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработанные тексты в одном списке:\n",
            "[['скромняга', 'бард', 'отдыхать', 'дело', 'геральт', 'ривия', 'песня', 'петь', 'сразиться', 'белый', 'волк', 'велиречивый', 'чёрт', 'эльф', 'покромсать', 'несчётный', 'когорта'], ['целиться', 'черта', 'рог', 'прямо', 'глаз', 'ведьмак', 'крикнуть', 'твой', 'смертный', 'час', 'ведьмак', 'заплатить', 'чеканный', 'монета', 'чеканный', 'монета', 'ведьмак', 'заплатить', 'зачесться', 'это'], ['эльф', 'прогнать', 'дальний', 'перевал', 'высокий', 'гора', 'вечный', 'привал', 'бить', 'бровь', 'глаз', 'ранить', 'человек', 'товарищ']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. Реализовать Bag of Words**"
      ],
      "metadata": {
        "id": "LwNOPQBr0tDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dict(texts: list[list[str]]) -> dict[str, int]:\n",
        "    vocab = []\n",
        "    for text in texts:\n",
        "        for word in text:\n",
        "            if word not in vocab:\n",
        "                vocab.append(word)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "EBUUbyfC1jIr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unic_words = make_dict(processed_texts)\n",
        "print(\"Словарь уникальных слов:\", unic_words, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfs86_PWvHxx",
        "outputId": "ab5140ba-da10-47dc-b0a5-0683d5d61530"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Словарь уникальных слов:\n",
            "['скромняга', 'бард', 'отдыхать', 'дело', 'геральт', 'ривия', 'песня', 'петь', 'сразиться', 'белый', 'волк', 'велиречивый', 'чёрт', 'эльф', 'покромсать', 'несчётный', 'когорта', 'целиться', 'черта', 'рог', 'прямо', 'глаз', 'ведьмак', 'крикнуть', 'твой', 'смертный', 'час', 'заплатить', 'чеканный', 'монета', 'зачесться', 'это', 'прогнать', 'дальний', 'перевал', 'высокий', 'гора', 'вечный', 'привал', 'бить', 'бровь', 'ранить', 'человек', 'товарищ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Bag_of_Words(texts: list[list[str]], vocab: list[str]) -> list[list[int]]:\n",
        "    bow = []\n",
        "\n",
        "    for text in texts:\n",
        "        word_count = [0] * len(vocab)\n",
        "\n",
        "        for word in text:\n",
        "            if word in vocab:\n",
        "                index = vocab.index(word)\n",
        "                word_count[index] += 1\n",
        "        bow.append(word_count)\n",
        "\n",
        "    return bow"
      ],
      "metadata": {
        "id": "gckZyQd279jI"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_matrix = Bag_of_Words(processed_texts, unic_words)\n",
        "print(\"Матрица Bag of Words:\")\n",
        "for row in bow_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhfTaaLE8YDh",
        "outputId": "e93ecf76-e465-409e-f11a-d500c19c9c52"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Матрица Bag of Words:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**III. Реализовать TF-IDF**"
      ],
      "metadata": {
        "id": "Jeh3-8PKAC8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_num_words(texts: list[list[str]]) -> list[int]:\n",
        "    word_counts = []\n",
        "    for text in texts:\n",
        "        word_counts.append(len(text))\n",
        "    return word_counts"
      ],
      "metadata": {
        "id": "3gqMj88nAG5-"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = count_num_words(processed_texts)\n",
        "print(\"Количество слов в каждом тексте:\", word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5izn5pSArN5",
        "outputId": "d41ab462-8661-444f-e86c-f26467cee1a2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов в каждом тексте: [17, 20, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tf(bow_matrix: list[list[int]], word_counts: list[int]) -> list[list[float]]:\n",
        "    tf_matrix = []\n",
        "\n",
        "    for i, row in enumerate(bow_matrix):\n",
        "        total_words = word_counts[i]\n",
        "        tf_row = []\n",
        "\n",
        "        for count in row:\n",
        "            if total_words > 0:\n",
        "                tf_row.append(count / total_words)\n",
        "            else:\n",
        "                tf_row.append(0)\n",
        "        tf_matrix.append(tf_row)\n",
        "\n",
        "    return tf_matrix"
      ],
      "metadata": {
        "id": "4qKWpLlQBwWP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_matrix = compute_tf(bow_matrix, word_counts)\n",
        "print(\"Матрица TF (Term Frequency):\")\n",
        "for row in tf_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuUZY7bqFUvR",
        "outputId": "947f2ab0-488d-4eec-a958-b072afb3ed29"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Матрица TF (Term Frequency):\n",
            "[0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.05, 0.05, 0.05, 0.05, 0.15, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.05, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_idf(texts: list[list[str]], vocab: list[str]) -> list[float]:\n",
        "    idf = []\n",
        "    num_docs = len(texts)\n",
        "\n",
        "    for word in vocab:\n",
        "        count = 0\n",
        "        for text in texts:\n",
        "            if word in text:\n",
        "                count += 1\n",
        "        idf.append(math.log((num_docs + 1) / (count + 1)) + 1)\n",
        "\n",
        "    return idf"
      ],
      "metadata": {
        "id": "WAp2UaMLByzy"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf_values = compute_idf(processed_texts, unic_words)\n",
        "print(\"Значения IDF (Inverse Document Frequency):\")\n",
        "print(idf_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2_aFjmuGrFV",
        "outputId": "4e6be3ce-01ff-4465-dd49-b91e4fe3ca7d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Значения IDF (Inverse Document Frequency):\n",
            "[1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.2876820724517808, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.2876820724517808, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.6931471805599454]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tfidf(tf_matrix: list[list[float]], idf_values: list[float]) -> list[list[float]]:\n",
        "    tfidf_matrix = []\n",
        "\n",
        "    for tf_row in tf_matrix:\n",
        "        tfidf_row = []\n",
        "\n",
        "        for i, tf_value in enumerate(tf_row):\n",
        "            tfidf_row.append(tf_value * idf_values[i])\n",
        "        tfidf_matrix.append(tfidf_row)\n",
        "\n",
        "    return tfidf_matrix"
      ],
      "metadata": {
        "id": "xmvg5SRJB1xL"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = compute_tfidf(tf_matrix, idf_values)\n",
        "print(\"Матрица TF-IDF:\")\n",
        "for row in tfidf_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9OQ-LFWB4AE",
        "outputId": "ec8c9462-0fa5-434e-8896-e7d6cfb543b6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Матрица TF-IDF:\n",
            "[0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.07574600426186946, 0.09959689297411443, 0.09959689297411443, 0.09959689297411443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08465735902799727, 0.08465735902799727, 0.08465735902799727, 0.08465735902799727, 0.06438410362258905, 0.2539720770839918, 0.08465735902799727, 0.08465735902799727, 0.08465735902799727, 0.08465735902799727, 0.16931471805599455, 0.16931471805599455, 0.16931471805599455, 0.08465735902799727, 0.08465735902799727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09197729088941291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09197729088941291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038, 0.12093908432571038]\n"
          ]
        }
      ]
    }
  ]
}